{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c584718",
   "metadata": {},
   "source": [
    "# 1. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd67af",
   "metadata": {},
   "source": [
    "#### Step 1: Collect 400 sentences randomly from the 1347 page book (FullText.pdf). \n",
    "#### Note: The following pages are NOT taken into account: \n",
    " *  The Hobbit: Page 1-2 (Cover Art, Special Note)\n",
    " *  The Fellowship of the Ring: Page 217-225 (Cover Art, Table of Contents, Foreword)\n",
    " *  The Two Towers: Page 664 (Cover Art)\n",
    " *  The Return of the King: Page 1021 (Cover Art)\n",
    " *  Page 1329 (Definitions of LotR related terminology) \n",
    " *  Page 1330-1342 (Maps)\n",
    " *  Page 1343-1346 (Geneology)\n",
    " *  Page 1347 (Disclaimer)\n",
    " \n",
    "#### This leaves us with 1315 pages (FullText_removed.pdf). Chapter Titles and Book Numerations are NOT considered as sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25def9a0",
   "metadata": {},
   "source": [
    "## 1.1 Text Extraction\n",
    "#### In order to annotate the words in Lord of the Rings, we need to extract the text from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3b49f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tobiasmichelsen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pdfminer.high_level import extract_text\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b4a467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Remove Chapter Titles and Book Numerations\n",
    "\n",
    "def filter_lines(lines):\n",
    "    chapter_pattern = re.compile(r'^Chapter \\w+', re.IGNORECASE)\n",
    "    book_pattern = re.compile(r'^\\* BOOK \\w+ \\*$', re.IGNORECASE)\n",
    "    title_pattern = re.compile(r'^[A-Za-z ]+$')  \n",
    "    \n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        if not (chapter_pattern.match(stripped_line) or\n",
    "                book_pattern.match(stripped_line) or\n",
    "                title_pattern.match(stripped_line)):\n",
    "            filtered_lines.append(stripped_line)\n",
    "    return filtered_lines\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "pdf_path = '/Users/tobiasmichelsen/Downloads/FullText_removed.pdf'\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "sentences = split_into_sentences(text)\n",
    "\n",
    "lines = text.splitlines()\n",
    "filtered_lines = filter_lines(lines)\n",
    "    \n",
    "    \n",
    "filtered_text = ' '.join(filtered_lines)\n",
    "sentences = split_into_sentences(filtered_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe18ea1",
   "metadata": {},
   "source": [
    "### Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3de4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Sentence:\n",
      "  In a hole in the ground there lived a hobbit.\n"
     ]
    }
   ],
   "source": [
    "print(\"Example Sentence:\")\n",
    "for sentence in sentences[0:1]:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782c4af9",
   "metadata": {},
   "source": [
    "## 1.2 Divide Sentences into Training/Test Subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9d35962",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "selected_sentences = random.sample(sentences, 1400)\n",
    "\n",
    "training_set = selected_sentences[:1000]\n",
    "test_set = selected_sentences[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cde6bd",
   "metadata": {},
   "source": [
    "### Save Subsets as .txt files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbd5fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_sentences.txt', 'w', encoding='utf-8') as train:\n",
    "    for sentence in training_set:\n",
    "        train.write(sentence + \"\\n\")\n",
    "        \n",
    "with open('testing_sentences.txt', 'w', encoding='utf-8') as test:\n",
    "    for sentence in test_set:\n",
    "        test.write(sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a70eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464656bd",
   "metadata": {},
   "source": [
    "## Annotation Guide (Before, Inside, Outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95b833",
   "metadata": {},
   "source": [
    "* O: Outside of any named entity. This tag is used for words that aren't part of an entity.\n",
    "\n",
    "* B-PER: Beginning of a person's name. This tag indicates that the word is the beginning of a person's name. If the name is only one word long, it still gets tagged as B-PER.\n",
    "\n",
    "* I-PER: Inside a person's name. This tag is used for all words that are part of a person's name but are not the first word.\n",
    "\n",
    "* B-LOC: Beginning of a location name. This tag denotes that the word is the beginning of a location name. Like B-PER, it's used even if the location is only one word.\n",
    "\n",
    "* I-LOC: Inside a location name. This tag is for words that are part of a location's name but are not the first word.\n",
    "\n",
    "* B-ORG: Beginning of an organization name. This tag indicates the start of an organization's name and is used even for single-word organization names.\n",
    "\n",
    "* I-ORG: Inside an organization name. It's used for words within an organization's name that are not the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa97d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting annotation for the training set...\n",
      "\n",
      "Annotating sentence: He  was interested in  roots and beginnings; he dived into  deep pools; he  burrowed under  trees and  growing plants; he tunnelled  into green  mounds;  and  he ceased to  look up at the hill-tops, or the leaves on trees, or  the flowers opening in the air: his head and his eyes were downward.\n",
      "\n",
      "Token: He\n",
      "O: Outside any named entity\n",
      "B-PER: Beginning of a person’s name\n",
      "I-PER: Inside a person’s name\n",
      "B-LOC: Beginning of a location\n",
      "I-LOC: Inside a location\n",
      "B-ORG: Beginning of an organization\n",
      "I-ORG: Inside an organization\n"
     ]
    }
   ],
   "source": [
    "def annotate_sentence(sentence, writer, sentence_id):\n",
    "    print(\"\\nAnnotating sentence:\", sentence)\n",
    "    for token in word_tokenize(sentence):\n",
    "        print(f\"\\nToken: {token}\")\n",
    "        for tag, desc in tag_description.items():\n",
    "            print(f\"{tag}: {desc}\")\n",
    "        tag_choice = input(\"Enter the tag for the token above: \")\n",
    "        writer.writerow([sentence_id, token, tag_choice])\n",
    "\n",
    "def handle_annotation(sentences_set, set_name):\n",
    "    file_path = f'{set_name}_annotations.csv'\n",
    "    with open(file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Check if we're starting fresh or appending\n",
    "        csvfile.seek(0, 2)  # Move to the end of file\n",
    "        if csvfile.tell() == 0:  # If file is empty, write the header\n",
    "            writer.writerow([\"Sentence_ID\", \"Token\", \"Tag\"])\n",
    "        for sentence_id, sentence in enumerate(sentences_set, start=1):\n",
    "            annotate_sentence(sentence, writer, sentence_id)\n",
    "            writer.writerow([])  # Add a blank row for readability\n",
    "\n",
    "# Starting annotation for the training set\n",
    "print(\"Starting annotation for the training set...\")\n",
    "handle_annotation(training_set, \"training\")\n",
    "\n",
    "# Starting annotation for the validation set\n",
    "print(\"\\nStarting annotation for the validation set...\")\n",
    "handle_annotation(validation_set, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4629e67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example sentence one.',\n",
       " 'Example sentence two.',\n",
       " 'In a hole in the ground there lived a hobbit.']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a9cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
